{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0J3MSJJaKMdVJl2+z9T72",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielbauer1979/MSDIA_PredictiveModelingAndMachineLearning/blob/main/GB888_VI_7_ImageClassificationViaCNNLab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab: Image Data and Image Classification via CNN\n",
        "\n",
        "In this lab, we will consider a second image classification problem on an alternative dataset: The Fashion MNIST dataset. Here, we predict what fashion item is shown on a given image.\n"
      ],
      "metadata": {
        "id": "2ITKe1htrCs5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is fairly analogous to the MNIST data -- it's also 28 by 28 pixel images, although in this case the images are of fashion items and the labels correspond to different fashion items -- here is the label\tdescription:\n",
        "- 0\tT-shirt/top\n",
        "- 1\tTrouser\n",
        "- 2\tPullover\n",
        "- 3\tDress\n",
        "- 4\tCoat\n",
        "- 5\tSandal\n",
        "- 6\tShirt\n",
        "- 7\tSneaker\n",
        "- 8\tBag\n",
        "- 9\tAnkle boot\n",
        "\n",
        "The problem, obviously, is to predict what kind of fashion item is on the image.\n",
        "\n",
        "## Load packages and Data\n",
        "\n",
        "Let's load some packages:"
      ],
      "metadata": {
        "id": "vrR68DM1ru0U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAWip7rArBmz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import random\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And let's take a look at the data:"
      ],
      "metadata": {
        "id": "bbNtc6_DUT3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "FK-vG-LArTWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "...and at a few of the items:"
      ],
      "metadata": {
        "id": "v0Iqkfz4ZdZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_index = 5\n",
        "print(y_train[image_index])\n",
        "plt.imshow(x_train[image_index], cmap='Greys')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "guViu6DOsAkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "...so this is a pullover."
      ],
      "metadata": {
        "id": "bBHcdS4lZh3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_index = 42\n",
        "print(y_train[image_index])\n",
        "plt.imshow(x_train[image_index], cmap='Greys')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oa6XY8TkrXhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So this is an ankle boot."
      ],
      "metadata": {
        "id": "XdBACgBQZmw5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Formatting\n",
        "\n",
        "As before, let's set a random seed and let's format the data for modeling:"
      ],
      "metadata": {
        "id": "aEkcI0Uea37l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "IPii2vzCa57L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feed-forward Neural Net\n",
        "\n",
        "Let's start by using a very similar neural net as we did in the previous application. We start by reshaping the inputs to simple vectors:"
      ],
      "metadata": {
        "id": "CKHYxnmmU60v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_trad = x_train.reshape(x_train.shape[0], 784)\n",
        "x_test_trad = x_test.reshape(x_test.shape[0], 784)\n",
        "\n",
        "x_train_trad = x_train_trad / 255\n",
        "x_test_trad = x_test_trad/ 255"
      ],
      "metadata": {
        "id": "5L6g2ODJU6c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And let's build a feed-forward model, as we did before. Again we use the soft-max function as the output layer for this multi-class problem, and we use 'categorical_crossentropy' as the (multi-class) loss function:"
      ],
      "metadata": {
        "id": "2ZdO5eyfVi-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(50, input_shape=(784, ), activation='relu', name='dense_1'))\n",
        "model.add(Dense(25, activation='relu', name='dense_2'))\n",
        "model.add(Dense(10, activation='softmax', name='dense_output'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "6nwjPR6bVVlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train it using 20 epochs:"
      ],
      "metadata": {
        "id": "hlQTHUbwVvOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train_trad, y_train, epochs=20, validation_data=(x_test_trad, y_test))"
      ],
      "metadata": {
        "id": "IVJniab0VP45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, again, we notice that after around 15 eopochs the validation fit doesn't seem to improve much. And, the acuracy is lower than 90%. So, it appears that the neural net is not working super well here. Let's try..."
      ],
      "metadata": {
        "id": "IdUkqs2tWXZ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Nets\n",
        "\n"
      ],
      "metadata": {
        "id": "JT5TFmfxV9c3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run the convolutional neural net, we use the native 2-dimensional tensor format:"
      ],
      "metadata": {
        "id": "WeOfIk5oWsOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)"
      ],
      "metadata": {
        "id": "BhDOviojU2-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And let's try buidiling a simple convolutional neural net:"
      ],
      "metadata": {
        "id": "Cr_FNCFmW0sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(img_rows, img_cols, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(img_rows/2, img_cols/2, 1)))\n",
        "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(img_rows/2, img_cols/2, 1)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(24, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "metadata": {
        "id": "Z1RHf8webMAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "iADFYRp3bRry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "5UsyOCtQbSrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So this seems to have few similar number of parameters as our neural net above. Let's train (to be fair, I experimented a little bit to get this):"
      ],
      "metadata": {
        "id": "hXQF0KghXCoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "px982NNvbYQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, it definitely takes longer to train. But, the accuracy definitely improves, though maybe not as drastically as we would hope. We may have to add more complexity to get to high accuracy, yet that requires a good amount of experimentation. As we indicated training these neural nets is part art aabd part science.\n",
        "\n",
        "Let's check out the predictions. Here we are going to generate a multi-class confusion matrix:"
      ],
      "metadata": {
        "id": "hshFma-OXi5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob = model.predict(x_test)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "conf_matrix = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues', xticklabels=list(range(num_classes)), yticklabels=list(range(num_classes)))\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TwVgtZN7I68C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is maybe not surpirisng that shirt and t-shirt present a challenge. Let's look at a few predictions:"
      ],
      "metadata": {
        "id": "zF0CsMOwJpmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_digit(image, digit, plt, i):\n",
        "    plt.subplot(4, 5, i + 1)\n",
        "    plt.imshow(image, cmap=plt.get_cmap('gray'))\n",
        "    plt.title(f\"Digit: {digit}\")\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "random.seed(13)\n",
        "\n",
        "plt.figure(figsize=(16, 10))\n",
        "for i in range(20):\n",
        "    image = random.choice(x_test).squeeze()\n",
        "    digit = np.argmax(model.predict(image.reshape((1, 28, 28, 1)))[0], axis=-1)\n",
        "    plot_digit(image, digit, plt, i)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Qc1JtL-Ndbil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0 T-shirt/top\n",
        "1 Trouser\n",
        "2 Pullover\n",
        "3 Dress\n",
        "4 Coat\n",
        "5 Sandal\n",
        "6 Shirt\n",
        "7 Sneaker\n",
        "8 Bag\n",
        "9 Ankle boot"
      ],
      "metadata": {
        "id": "k5icQ0nxb0F4"
      }
    }
  ]
}