{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNML2j91XkYsX2Ag9M/bPr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielbauer1979/MSDIA_PredictiveModelingAndMachineLearning/blob/main/GB886_VI_4_TelCoRidgeExample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Regularization Approaches: Ridge and LASSO Regression\n",
        "\n",
        "## Ridge and LASSO Regression\n",
        "\n",
        "Ridge and LASSO regression are both examples of *regularized* regression approaches.  In what follows, we will first briefly review the corresponding approaches, and particularly highlight how they differ from their unregularized counterparts.   We then will work through a simulated example to become familiar with the impact of the *tuning parameter* on the resulting coefficient estimates.  We will also determine the in- and out-of-sample fit depending on the choice of the tuning parameter, uncovering a familiar relationship.\n",
        "\n",
        "## Review of Concepts and Maths\n",
        "\n",
        "In a conventional (linear) regression problem with independent variables $x_i$ and depedent variables $y_i$, we are determining the best fit in the least-squares sense:\n",
        "$$\n",
        "\\hat{\\beta}^{\\text{OLS}} = \\text{argmin}_{\\beta}\\left\\{\\sum_{i=1}^n \\left(y_i - \\left(\\beta_0 + \\sum_{j=1}^p \\beta_j\\,x_{i,j}\\right)\\right)^2 \\right\\}.\n",
        "$$\n",
        "Within a *regularized* approach, we now include penalties for choosing many or large parameters:\n",
        "$$\n",
        "\\hat{\\beta}^{\\text{REG}}_\\lambda = \\text{argmin}_{\\beta}\\left\\{\\sum_{i=1}^n \\left(y_i - \\left(\\beta_0 + \\sum_{j=1}^p \\beta_j\\,x_{i,j}\\right)\\right)^2 + \\lambda \\times R(\\beta) \\right\\}.\n",
        "$$\n",
        "Here, $R(\\beta)$ is a so-called *regularization* term that imposes a penalty on the complexity of the regression equation.  In particular, within Rigde regression the penalty term is *quadratic*, $R(\\beta) = \\sum_{j=1}^p \\beta_j^2,$ wheras the LASSO uses an L1 penalty, $R(\\beta) = \\sum_{j=1}^p |\\beta_j|.$  \n",
        "\n",
        "We call $\\lambda$ the *tuning parameter*, and it governs how sizable the complexity penalty will be.  In particular, note that for $\\lambda=0$ we are back to the unregularized problem, whereas for large lambda the penalty will be severe -- so this will lead to *shrinkage* of the coefficient estimates.  As $\\lambda$ becomes large and larger, the prediction will more and more closely resemble a *constant* prediction, $\\hat{y}_i = \\beta_0.$  Thus, the choice of the tuning parameter will directly be related to trading off a reduction in variance (due to shrinkage) with an increase in bias (due to the less flexible model fit).  Again, we will explore these aspects in more detail in the context of our example below.\n",
        "\n",
        "## Application: Telecom Work Measurement Study Again\n",
        "\n",
        "To showcase the regularization approaches discussed here, we go back to our  [Telecom Work Measurement Study](http://www.statsci.org/data/oz/telecom.html) example. Here, we predict hours worked in a given section based on characteristics.\n",
        "\n",
        "### Preliminaries\n",
        "\n",
        "As usually, we start by loading some of the packages we will use and the data. We use the \"full\" data from both sub-datasets:"
      ],
      "metadata": {
        "id": "kTwZI0SwiAE5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IOkuUgBh9v7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler #Recall that for regularized approaches we need to scale our features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/danielbauer1979/MSDIA_PredictiveModelingAndMachineLearning.git"
      ],
      "metadata": {
        "id": "uXLnk1rqiypy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_base = pd.read_csv('MSDIA_PredictiveModelingAndMachineLearning/GB886_V_4_tel_base.csv')\n",
        "data_addtl = pd.read_csv('MSDIA_PredictiveModelingAndMachineLearning/GB886_V_4_tel_addtl.csv')\n",
        "data = pd.concat([data_base, data_addtl], ignore_index=True)"
      ],
      "metadata": {
        "id": "9PRMS5iuIL-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline Linear Regression\n",
        "\n",
        "We start by re-running the baseline linear regression using all features:"
      ],
      "metadata": {
        "id": "xQAxtlNbRxkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = data['Hours']\n",
        "X = data.drop(columns=['Hours'])\n",
        "X = sm.add_constant(X)\n",
        "model_full = sm.OLS(y, X).fit()\n",
        "model_full.summary()"
      ],
      "metadata": {
        "id": "_-2jo6XSIsmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, recall that for regularized approach, we will want to scale our features. The [standard scaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) simply subtracts the mean for each feature and divides each feature by its standard error, so that the resulting variance of each feature is the same at one:"
      ],
      "metadata": {
        "id": "fzhF8k6uR6MO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(columns=['Hours'])\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled = sm.add_constant(X_scaled)"
      ],
      "metadata": {
        "id": "2CBy-Op8JIEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's rerun the OLS linear regression:"
      ],
      "metadata": {
        "id": "_uG8XZEsSfv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_full = sm.OLS(y,X_scaled).fit()\n",
        "model_full.summary()"
      ],
      "metadata": {
        "id": "c--sFrJgJUt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the cofficients change. However, note that the R-squared and the other statistics remain identical. This is no surprise because the predictions remain identical. All we do is change the \"units\" of the features (think about changing currencies)."
      ],
      "metadata": {
        "id": "5Aqx7I8jSjM0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ridge Regression\n",
        "\n",
        "Let's commence with running the rigde regression using 'statsmodels' (where it can be implemented as a special case of the \"elastic net\" regression, we will come back to this). We start running the model with a zero penalty (alpha):"
      ],
      "metadata": {
        "id": "1gt9w3B0S6T_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ridge = sm.OLS(y, X_scaled).fit_regularized(method='elastic_net', alpha=0.0, L1_wt=0.0)"
      ],
      "metadata": {
        "id": "429z_w2QIvkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ridge.params"
      ],
      "metadata": {
        "id": "wUxy8huXJ8PM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, what we see is that the coefficients here are exactly the same as in the OLS case---which is no surprise because we have no penalty!\n",
        "\n",
        "However, if we go to a penalty of one, the coefficents change:"
      ],
      "metadata": {
        "id": "mywanyZuTRnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ridge = sm.OLS(y, X_scaled).fit_regularized(method='elastic_net', alpha=1.0, L1_wt=0.0)\n",
        "model_ridge.params"
      ],
      "metadata": {
        "id": "0wLfqYe4N6xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, 'statmodels' does not have the same convenient output functionality. Therefore, we instead will go to the (more powerful) predictive modeling package 'sklearn'. Let's plot the R-squared, the MSE, and the coefficients for the features SOA, SOB, and SOC to illustrate the impact of the penalty parameter on the coefficients:"
      ],
      "metadata": {
        "id": "s13iDxb3U0bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "alpha_values = np.linspace(0, 500, 500)\n",
        "r2_values = []\n",
        "mse_values = []\n",
        "coef_x3 = []\n",
        "coef_x4 = []\n",
        "coef_x5 = []\n",
        "\n",
        "for alpha in alpha_values:\n",
        "  model_ridge = Ridge(alpha=alpha)\n",
        "  model_ridge.fit(X_scaled, y)\n",
        "  y_pred = model_ridge.predict(X_scaled)\n",
        "  r2 = 1 - np.sum((y - y_pred)**2) / np.sum((y - np.mean(y))**2)\n",
        "  mse = np.mean((y - y_pred)**2)\n",
        "  r2_values.append(r2)\n",
        "  mse_values.append(mse)\n",
        "  coef_x3.append(model_ridge.coef_[3])\n",
        "  coef_x4.append(model_ridge.coef_[4])\n",
        "  coef_x5.append(model_ridge.coef_[5])\n",
        "\n",
        "# Plot MSE and R^2\n",
        "fig, ax1 = plt.subplots()\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('Alpha')\n",
        "ax1.set_ylabel('MSE', color=color)\n",
        "ax1.plot(alpha_values, mse_values, color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('R-squared', color=color)\n",
        "ax2.plot(alpha_values, r2_values, color=color)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.title('MSE and R-squared vs. Alpha (sklearn)')\n",
        "plt.show()\n",
        "\n",
        "# Plot coefficients\n",
        "plt.plot(alpha_values, coef_x3, label='x3')\n",
        "plt.plot(alpha_values, coef_x4, label='x4')\n",
        "plt.plot(alpha_values, coef_x5, label='x5')\n",
        "plt.xlabel('Alpha')\n",
        "plt.ylabel('Coefficient Value')\n",
        "plt.title('Coefficients vs. Alpha (sklearn)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "50tG7Y1ONCNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's also generate predictions for the last model with the highest penalty:"
      ],
      "metadata": {
        "id": "UklGf9OpWNkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ridge.predict(X_scaled)"
      ],
      "metadata": {
        "id": "VN2GTvkfWE1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, we notice all predictions are very similar---and very close to the mean of y:"
      ],
      "metadata": {
        "id": "JDbRz1kNWZOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(y)"
      ],
      "metadata": {
        "id": "SGx3_heUWT-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hence, we see the effect that the predictions are pulled to the mean!"
      ],
      "metadata": {
        "id": "3k9PCCjAWfq-"
      }
    }
  ]
}