{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielbauer1979/MSDIA_PredictiveModelingAndMachineLearning/blob/main/GB886_IV_12_CreditCardCaseStudy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Credit Card Default Case Study\n",
        "\n"
      ],
      "metadata": {
        "id": "bFNuMreLe4xh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQkFLmYWqmN3"
      },
      "source": [
        "In this tutorial, we will use logistic and probit regression to predict credit card default scores.\n",
        "\n",
        "We rely on the dataset `pa_data_UCI_Credit_Card.csv` from the UCI Machine Learning Repository (Lichman, M., 2013. [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml). Irvine, CA: University of California, School of Information and Computer Science).  This datasets provides credit card defaults for customers in Taiwan.  We are given some demographic information ($X_1$-$X_5$), the previous history of payments ($X_6$-$X_{11}$), the amount of previous bills ($X_{12}$-$X_{17}$), and amounts of previous payments ($X_{18}$-$X_{23}$).  Finally, variable 24 is our target, whetyher there was a default in the next months.\n",
        "\n",
        "\n",
        "As always, let's start with importing the libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANNbSksYqWS3"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report, precision_score, roc_curve, auc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's load the dataset:"
      ],
      "metadata": {
        "id": "okvP8ddqfGwX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70QK-AnxqWTB"
      },
      "source": [
        "!git clone https://github.com/danielbauer1979/MSDIA_PredictiveModelingAndMachineLearning.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzW2COB-qWTC"
      },
      "source": [
        "mydata = pd.read_csv('MSDIA_PredictiveModelingAndMachineLearning/GB886_IV_12_UCI_Credit_Card.csv', index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Exploration and Preparation"
      ],
      "metadata": {
        "id": "Y4q8flL3fLw8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ7xrrgfqWTC"
      },
      "source": [
        "mydata.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at some aggregate statistics."
      ],
      "metadata": {
        "id": "bdiFv-p4fQ1j"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWYoH_ngqWTD"
      },
      "source": [
        "mydata.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, a number of the variables are included numerically but really they have factor character, particularly Gender (1 = male; 2 = female), Education (1 = graduate school; 2 = university; 3 = high school; 4 = others), Marital status (1 = married; 2 = single; 3 = others), and default payment. Let's store them as factors.  We will do the same for history of past payment ($X_6$-$X_{11}$), although they really have ordinal character."
      ],
      "metadata": {
        "id": "651lfbJMgE04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "factor = ['SEX', 'EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'default.payment.next.month']"
      ],
      "metadata": {
        "id": "ZAwjAtXxgJ9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also, a number of the levels occur very sparsely: there are 11 levels for all the `PAY` variables, but only the first six seem to be frequent.  So let's collapse levels 7 through 11 to one:"
      ],
      "metadata": {
        "id": "23vcLxDYgRcb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr5L46eWqWTD"
      },
      "source": [
        "mydata['PAY_0'][mydata['PAY_0']>4] = 4\n",
        "mydata['PAY_2'][mydata['PAY_2']>4] = 4\n",
        "mydata['PAY_3'][mydata['PAY_3']>4] = 4\n",
        "mydata['PAY_4'][mydata['PAY_4']>4] = 4\n",
        "mydata['PAY_5'][mydata['PAY_5']>4] = 4\n",
        "mydata['PAY_6'][mydata['PAY_6']>4] = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, generate dummies:"
      ],
      "metadata": {
        "id": "Q4xm1bOegjmw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rfdm9IdqWTE"
      },
      "source": [
        "mydata_numcols = mydata.drop(columns = factor)\n",
        "mydata_faccols = mydata[factor].astype('category')\n",
        "dummies = pd.get_dummies(mydata_faccols, drop_first=True)\n",
        "mydata = pd.concat([mydata_numcols, dummies], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And Let's relabel the long name of the dependent variable:"
      ],
      "metadata": {
        "id": "tSOZn3i-gtKf"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCaaHETUqWTF"
      },
      "source": [
        "mydata = mydata.rename(columns={\"default.payment.next.month_1\": \"default\"})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look:"
      ],
      "metadata": {
        "id": "fwfWHqovgynk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UfQEQiEqWTF"
      },
      "source": [
        "mydata.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zibCpbmrqWTG"
      },
      "source": [
        "mydata.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check a correlation plot to make sure none of the variables is extremely correlated:"
      ],
      "metadata": {
        "id": "HdHdC-Kyg5A2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask = np.triu(np.ones_like(mydata.corr(), dtype=bool))\n",
        "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
        "sns.heatmap(mydata.corr(), mask=mask, cmap=cmap, vmax=.3, center=0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
      ],
      "metadata": {
        "id": "xJPkW_qwwKys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So it looks like the bill amounts are highly correlated.  Let's just keep the most recent one and then the average of all of them:\n"
      ],
      "metadata": {
        "id": "ihKWiDkphM_3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLIXJYlyqWTH"
      },
      "source": [
        "mydata.insert(17, \"BILL_AVG\", (mydata['BILL_AMT1']+mydata['BILL_AMT2']+mydata['BILL_AMT3']+mydata['BILL_AMT4']+mydata['BILL_AMT5']+mydata['BILL_AMT6'])/6, True)\n",
        "mydata = mydata.rename(columns={\"BILL_AMT1\": \"BILL_REC\"})\n",
        "del mydata['BILL_AMT2']\n",
        "del mydata['BILL_AMT3']\n",
        "del mydata['BILL_AMT4']\n",
        "del mydata['BILL_AMT5']\n",
        "del mydata['BILL_AMT6']\n",
        "mydata.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's save the dataset so that we can use it in coming tutorials without having to go through this procedure again:"
      ],
      "metadata": {
        "id": "IdJvKO_FhSkU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRIpqkhsqWTH"
      },
      "source": [
        "mydata.to_csv('GB886_IV_12_UCI_Credit_Card_prepped.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictive Modeling: Logistic Regression"
      ],
      "metadata": {
        "id": "Xwm41PjahXf0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define:\n"
      ],
      "metadata": {
        "id": "e80dFeKijLfn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK8HBxrBqWTI"
      },
      "source": [
        "y = mydata['default']\n",
        "X = mydata.drop(columns = ['default'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And let's run our logistic regression model:"
      ],
      "metadata": {
        "id": "dx4RzeO0ksTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_mod = sm.Logit(y, sm.add_constant(X).astype(float))\n",
        "logistic_mod = logistic_mod.fit(maxiter = 10000)\n",
        "print(logistic_mod.summary())"
      ],
      "metadata": {
        "id": "yJRgok_IQFBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we notice the limit balance and the pay amounts have a negative association with default, whereas the bill average and the bill average have a positive association with default. Several of the demographic variables seem to matter, too!"
      ],
      "metadata": {
        "id": "m--mKwsWWfXo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(I also ran this regression using sklearn, but the coefficients were quite different. There are a few reasons that I explored, but in the end the results still did not align. Given that there is a numerical procedure involved in solving the model, sometimes small inconsistencies can lead to substantial differences in coefficients.)"
      ],
      "metadata": {
        "id": "l1BP7jjcjPzy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the predictions:"
      ],
      "metadata": {
        "id": "PxNquZnljYn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p_x = logistic_mod.predict()\n",
        "y_hat = (p_x > 0.5)"
      ],
      "metadata": {
        "id": "b-CbR92JxFfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at the **confusion table**:"
      ],
      "metadata": {
        "id": "ESvCIt_xyseC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat = pd.crosstab(y, y_hat, rownames=['Actual Defaults'], colnames=['Predicted Defualts'])\n",
        "# Add row and column sums\n",
        "conf_mat.loc['Column_Total']= conf_mat.sum(numeric_only=True, axis=0)\n",
        "conf_mat.loc[:,'Row_Total'] = conf_mat.sum(numeric_only=True, axis=1)\n",
        "print(conf_mat)"
      ],
      "metadata": {
        "id": "IxKjglK_xxPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And let's calculate some resulting metrics:"
      ],
      "metadata": {
        "id": "o4rroO9Vy1kv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TPR = 2372 / 6636 # True-Positive Rate\n",
        "TNR = 22272 / 23364 # True-Negative Rate\n",
        "MCR = (1092+4264)/30000 # Miss Classification Rate\n",
        "print('TPR =', TPR)\n",
        "print('TNR =', TNR)\n",
        "print('MCR =', MCR)"
      ],
      "metadata": {
        "id": "5J-c4YuiyWk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "So we are missing a few, yet the misclassification rate seems reasonable.\n",
        "\n",
        "Let's consider the **ROC curve**:"
      ],
      "metadata": {
        "id": "4pC5K5zNjbXe"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIY4iAiwqWTL"
      },
      "source": [
        "fpr, tpr, threshold = roc_curve(y, p_x)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The AUC is 77%. This is not very high, but again -- in line with the interpretation of R-squarec -- we should not think about AUCs below 90% or 80% as a not usefull classification model. Rather, this result implies that there is \"noise\" in the model that cannot be explained by our model. So, we need to consider this aspect in business applications: Mislabeling is not rare in this setting."
      ],
      "metadata": {
        "id": "tnAJTmNsk-j1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Validation\n",
        "\n",
        "To validate our model, let's first generate a calibration plot. As a reminder, calibration plots bin the data by predicted probabilities and then plot the predicted probabilies (x-axis) versus actual frequencies of defaults (y-axis). a \"perfect\" model would generate predictions in line with observed frequencies, so the observations should be on the line with slope one:\n",
        "\n"
      ],
      "metadata": {
        "id": "9EgbRr_N6ONp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mydata['P_default'] = logistic_mod.predict()\n",
        "mydata['decile'] = pd.qcut(mydata['P_default'], 20, labels=False)\n",
        "\n",
        "# Calculate the average predicted probability and actual default rate for each decile\n",
        "decile_stats = mydata.groupby('decile').agg({'P_default': 'mean', 'default': 'mean'})\n",
        "\n",
        "# Scatterplot of predicted probabilities vs actual default rates\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(decile_stats['P_default'], decile_stats['default'])\n",
        "plt.xlabel('Predicted Probability (Decile)')\n",
        "plt.ylabel('Actual Default Rate')\n",
        "plt.title('Calibration Plot for Logistic Regression')\n",
        "\n",
        "# Add a line with slope 1\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xoMgQYDR6Nli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the points do not lie on the line and there appear to be systematic deviations...\n",
        "\n",
        "Let's evaluate a chi-squared statistic (thus is not quite the Hosmer-Lemeshow statistic, we are just using expected values in the denominator; the Hosmer-Lemeshow statistic will be greater!):"
      ],
      "metadata": {
        "id": "WO90ujikmxWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate observed and expected frequencies for each decile\n",
        "observed = mydata.groupby('decile')['default'].sum()\n",
        "expected = mydata.groupby('decile')['P_default'].sum()\n",
        "\n",
        "# Calculate the Chi-squared statistic\n",
        "xs_statistic = np.sum((observed - expected)**2 / expected)\n",
        "\n",
        "# Degrees of freedom (number of groups - 1)\n",
        "df = 20 - 1\n",
        "\n",
        "# Calculate the p-value\n",
        "from scipy.stats import chi2\n",
        "p_value = 1 - chi2.cdf(xs_statistic, df)\n",
        "\n",
        "print(\"Chi-squared Statistic:\", xs_statistic)\n",
        "print(\"P-value:\", p_value)"
      ],
      "metadata": {
        "id": "2rYaqT_Z7k_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the test rejects the model... Let's see if probit regression yields an improvement."
      ],
      "metadata": {
        "id": "Vzsq9Ed4oCmz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictive Modeling: Probit Regression\n",
        "\n",
        "Let's run the probit regression which is also available in the statsmodels library:"
      ],
      "metadata": {
        "id": "8B9yfAuOoS_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "probit_mod = sm.Probit(y, sm.add_constant(X).astype(float))\n",
        "probit_result = probit_mod.fit(maxiter=10000)\n",
        "print(probit_result.summary())"
      ],
      "metadata": {
        "id": "xkYasJeq-KcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The signs of the coefficients are in line with the logistic regression table. The exact numbers of the coefficients are more tricky to compare, because of the difference in link function.\n",
        "\n",
        "Let's look at the calibration plot in this case:"
      ],
      "metadata": {
        "id": "b2vgfZoko04f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict probabilities using the probit model\n",
        "mydata['P_default_probit'] = probit_result.predict()\n",
        "\n",
        "# Create deciles based on predicted probabilities from the probit model\n",
        "mydata['decile_probit'] = pd.qcut(mydata['P_default_probit'], 20, labels=False)\n",
        "\n",
        "# Calculate average predicted probability and actual default rate for each decile (probit)\n",
        "decile_stats_probit = mydata.groupby('decile_probit').agg({'P_default_probit': 'mean', 'default': 'mean'})\n",
        "\n",
        "# Scatterplot for probit model\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(decile_stats_probit['P_default_probit'], decile_stats_probit['default'])\n",
        "plt.xlabel('Predicted Probability (Decile) - Probit')\n",
        "plt.ylabel('Actual Default Rate')\n",
        "plt.title('Calibration Plot for Probit Regression')\n",
        "\n",
        "# Add a line with slope 1\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nJTEco6l-Ye4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, it looks very similar. Let's check the statistical test:"
      ],
      "metadata": {
        "id": "gWRw-32wtCbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate observed and expected frequencies for each decile (probit)\n",
        "observed_probit = mydata.groupby('decile_probit')['default'].sum()\n",
        "expected_probit = mydata.groupby('decile_probit')['P_default_probit'].sum()\n",
        "\n",
        "# Calculate the Hosmer-Lemeshow statistic for the probit model\n",
        "xs_statistic_probit = np.sum((observed_probit - expected_probit)**2 / expected_probit)\n",
        "\n",
        "# Calculate the Chi-squared statistic\n",
        "df = 20 - 1\n",
        "\n",
        "# Calculate the p-value for the probit model\n",
        "from scipy.stats import chi2\n",
        "p_value_probit = 1 - chi2.cdf(xs_statistic_probit, df)\n",
        "\n",
        "print(\"Chi-square Statistic (Probit):\", xs_statistic_probit)\n",
        "print(\"P-value (Probit):\", p_value_probit)"
      ],
      "metadata": {
        "id": "Fs-9ChOt-oOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the test metric is slightly smaller, indicating a better fit. But the perfromance does not seem substantially better.\n",
        "\n",
        "Let's look at the ROC curve:"
      ],
      "metadata": {
        "id": "0vSZs568th5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "probs_probit = probit_result.predict()\n",
        "fpr_probit, tpr_probit, thresholds_probit = roc_curve(y, probs_probit)\n",
        "roc_auc_probit = auc(fpr_probit, tpr_probit)\n",
        "\n",
        "# Plot ROC curve for probit model\n",
        "plt.figure()\n",
        "plt.plot(fpr_probit, tpr_probit, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_probit)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic - Probit Model')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y--hnbAv-x-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, very similar to the logistic model. Let's check the confusion table:"
      ],
      "metadata": {
        "id": "kLTuDiJ-4Q1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify predictions based on a 0.5 cutoff\n",
        "y_pred = (probs_probit > 0.5).astype(int)\n",
        "\n",
        "# Generate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y, y_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "id": "6Xz2NPg-_BMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agai, very similar."
      ],
      "metadata": {
        "id": "-5LqFCnP4iK5"
      }
    }
  ]
}