{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielbauer1979/MSDIA_PredictiveModelingAndMachineLearning/blob/main/GB888_IV_11_RandomForestAndBoostingForRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest And Boosting For Regression\n",
        "\n",
        "\n",
        "In this tutorial, we then use random forests and boosted trees in a regression setting: We are going to predict house prices based on a dataset from a specific town.\n",
        "\n",
        "As usually, let's start with loading the relevant libaries."
      ],
      "metadata": {
        "id": "vj5Ol0L_AMoq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vCC-SQb7VRR"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import graphviz\n",
        "import pydot\n",
        "from io import StringIO\n",
        "\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LassoCV, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "import sklearn.metrics as metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRIewfHHQt-u"
      },
      "source": [
        "## Setting and Data\n",
        "\n",
        "As mentioned, we are going to use a well-known dataset, namely a the House Price Data from Ames, Iowa, which is used in an [ongoing data science competion on kaggle](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques). It includes 79 features describing details of 1,460 residential homes in Ames, Iowa. We are trying to predict how much a house with given features would be sold for."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oczDAE4wjt4"
      },
      "source": [
        "### Load the data\n",
        "\n",
        "We start by loading the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joqrQm2gSDdZ"
      },
      "source": [
        "!git clone https://github.com/danielbauer1979/MSDIA_PredictiveModelingAndMachineLearning.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jILOaSki7VRX"
      },
      "source": [
        "house = pd.read_csv('MSDIA_PredictiveModelingAndMachineLearning/GB888_IV_11_HousePriceData.csv')\n",
        "house.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "house.shape"
      ],
      "metadata": {
        "id": "AL_WQm2LMuyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWBCjNh2woDd"
      },
      "source": [
        "It turns out there are many missing variables (NaN), so we need to go though some steps to...\n",
        "\n",
        "### Prepare the Data\n",
        "\n",
        "We will follow a relatively simple procedure: We'll check for features with lots of missing values, and then delete these features. We will then just drop the observations with missing features. Of course, more advanced methods such as imputing the missing variables would be possible.\n",
        "\n",
        "Let's first look for features with missing variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abomVqWFlxVo"
      },
      "source": [
        "pd.set_option(\"display.max_rows\", None)\n",
        "house.isnull().sum(axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, let's drop those with lots of missing values:"
      ],
      "metadata": {
        "id": "aQDVah9OC88m"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuUNldN6nzFE"
      },
      "source": [
        "house = house.drop(columns=['Id','LotFrontage','Alley','MasVnrType', 'BsmtQual', 'BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','FireplaceQu','GarageType','GarageYrBlt','GarageFinish','GarageQual','GarageCond','PoolQC','Fence','MiscFeature'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And let's then drop the observations with missing variables:"
      ],
      "metadata": {
        "id": "Xbz4SZH8DB9J"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6FzvzLRrYmx"
      },
      "source": [
        "house = house.dropna()\n",
        "house.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "house.shape"
      ],
      "metadata": {
        "id": "1Fi8IlWYM7JQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we only dropped relatively few observations, which is good!\n",
        "\n",
        "Next, we will convert the factor variables to dummies and scale the numerical variables:"
      ],
      "metadata": {
        "id": "cXPAGvUyDIDg"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ77WRKus_Xc"
      },
      "source": [
        "col_types = house.columns.to_series().groupby(house.dtypes).groups\n",
        "numerics = list(house.select_dtypes(include=['int64']).columns)\n",
        "factors = list(house.select_dtypes(include=['object']).columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSHiS4cbrBDD"
      },
      "source": [
        "house_numcols = house[numerics].drop(columns = ['SalePrice'])\n",
        "house_faccols = house[factors]\n",
        "dummies = pd.get_dummies(house_faccols, drop_first=True)\n",
        "house_numcols_sc_0 = scale(house_numcols)\n",
        "house_numcols_sc = pd.DataFrame(data=house_numcols_sc_0, columns = house_numcols.columns, index = dummies.index)\n",
        "house_sc = pd.concat([house_numcols_sc, dummies], axis = 1)\n",
        "house_sc = pd.concat([house_sc, house['SalePrice']], axis =1)\n",
        "house_sc = house_sc.rename(columns={\"SalePrice\":\"Y\"})\n",
        "house_sc.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, we have the scaled numerical variables, the factor variables as dummies, and then our target variable 'Y'.\n",
        "\n",
        "Let's now..."
      ],
      "metadata": {
        "id": "Xoxto7ZSDhf4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALiq7uTFwvZ7"
      },
      "source": [
        "### Explore the data\n",
        "\n",
        "... a bit. I am borrowing this plot from an [article](https://towardsdatascience.com/machine-learning-with-python-regression-complete-tutorial-47268e546cea) I liked:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahz5pTT-xodx"
      },
      "source": [
        "x = \"Y\"\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2,  sharex=False, sharey=False)\n",
        "fig.suptitle(x, fontsize=20)\n",
        "### distribution\n",
        "ax[0].title.set_text('distribution')\n",
        "variable = house_sc[x].fillna(house_sc[x].mean())\n",
        "breaks = np.quantile(variable, q=np.linspace(0, 1, 11))\n",
        "variable = variable[ (variable > breaks[0]) & (variable <\n",
        "                    breaks[10]) ]\n",
        "sns.distplot(variable, hist=True, kde=True, kde_kws={\"shade\": True}, ax=ax[0])\n",
        "des = house_sc[x].describe()\n",
        "ax[0].axvline(des[\"25%\"], ls='--')\n",
        "ax[0].axvline(des[\"mean\"], ls='--')\n",
        "ax[0].axvline(des[\"75%\"], ls='--')\n",
        "ax[0].grid(True)\n",
        "des = round(des, 2).apply(lambda x: str(x))\n",
        "box = '\\n'.join((\"min: \"+des[\"min\"], \"25%: \"+des[\"25%\"], \"mean: \"+des[\"mean\"], \"75%: \"+des[\"75%\"], \"max: \"+des[\"max\"]))\n",
        "ax[0].text(0.95, 0.95, box, transform=ax[0].transAxes, fontsize=10, va='top', ha=\"right\", bbox=dict(boxstyle='round', facecolor='white', alpha=1))\n",
        "### boxplot\n",
        "ax[1].title.set_text('outliers (log scale)')\n",
        "tmp_dtf = pd.DataFrame(house_sc[x])\n",
        "tmp_dtf[x] = np.log(tmp_dtf[x])\n",
        "tmp_dtf.boxplot(column=x, ax=ax[1])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, we see that the data is a bit skewed, see the disytribution on the left-hand side. And there are quite a few outliers on the log-scale, meaning there are some very cheap and very expensive homes. This may be a challenge for linear-regression modeling."
      ],
      "metadata": {
        "id": "k-GPWOzjD_33"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will split the data into *three* parts. One training set consisting of 60% of our data, one validation set we use for tuning models (20%), and finally a test set we use for comparing models (20%):"
      ],
      "metadata": {
        "id": "BLA0BIGxN0bg"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55xSsRHJLUuu"
      },
      "source": [
        "np.random.seed(42)\n",
        "train, test = train_test_split(house_sc, test_size = 0.4)\n",
        "val, test = train_test_split(test, test_size = 0.5)\n",
        "X_train = train.drop(columns = ['Y']).values\n",
        "y_train = train['Y'].values\n",
        "X_val = val.drop(columns = ['Y']).values\n",
        "y_val = val['Y'].values\n",
        "X_test = test.drop(columns = ['Y']).values\n",
        "y_test = test['Y'].values\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predictive Modeling\n",
        "\n",
        "Let's start building and comparing model. As a baseline, let's run a...\n",
        "\n",
        "###LASSO Regression Model\n",
        "\n",
        "We use LassoCV for tuning parameter selection:"
      ],
      "metadata": {
        "id": "0Sri8kbbORny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_cv = LassoCV(alphas=np.logspace(-3, 3, 100), cv=5, random_state=0) # Increased alphas for wider search\n",
        "lasso_cv.fit(X_train, y_train)\n",
        "alpha_optimal = lasso_cv.alpha_"
      ],
      "metadata": {
        "id": "FLcBvtLxPiVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_model = Lasso(alpha=alpha_optimal)\n",
        "lasso_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "7ZoW4Q6-Ps3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_lasso_pred = lasso_model.predict(X_test)"
      ],
      "metadata": {
        "id": "kXnL-fhQP3aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Kpi\n",
        "print(\"R2 (explained variance):\", round(metrics.r2_score(y_test, y_lasso_pred), 2))\n",
        "print(\"Mean Absolute Perc Error (Σ(|y-pred|/y)/n):\", round(np.mean(np.abs((y_test-y_lasso_pred)/y_lasso_pred)), 2))\n",
        "print(\"Mean Absolute Error (Σ|y-pred|/n):\", \"{:,.0f}\".format(metrics.mean_absolute_error(y_test, y_lasso_pred)))\n",
        "print(\"Root Mean Squared Error (sqrt(Σ(y-pred)^2/n)):\", \"{:,.0f}\".format(np.sqrt(metrics.mean_squared_error(y_test, y_lasso_pred))))\n",
        "## residuals\n",
        "residuals = y_test - y_lasso_pred\n",
        "max_error = max(residuals) if abs(max(residuals)) > abs(min(residuals)) else min(residuals)\n",
        "max_idx = list(residuals).index(max(residuals)) if abs(max(residuals)) > abs(min(residuals)) else list(residuals).index(min(residuals))\n",
        "max_true, max_pred = y_test[max_idx], y_lasso_pred[max_idx]\n",
        "print(\"Max Error:\", \"{:,.0f}\".format(max_error))"
      ],
      "metadata": {
        "id": "rfIf63tJP5Yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lcvdPSFP6Us"
      },
      "source": [
        "### Random Forest Model\n",
        "\n",
        "Let's now consider a random forest model. Let's start with a model under default parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qrbc0IG2P9wB"
      },
      "source": [
        "house_rf = RandomForestRegressor(random_state=1)\n",
        "house_rf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's predict in the test set:"
      ],
      "metadata": {
        "id": "j_C7YwyiSsPC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExauyByLHJds"
      },
      "source": [
        "y_rf_test_pred = house_rf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And let's check the performance:"
      ],
      "metadata": {
        "id": "_KxIytX1Svs3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSwpyOQZ3i0C"
      },
      "source": [
        "## Kpi\n",
        "print(\"R2 (explained variance):\", round(metrics.r2_score(y_test, y_rf_test_pred), 2))\n",
        "print(\"Mean Absolute Perc Error (Σ(|y-pred|/y)/n):\", round(np.mean(np.abs((y_test-y_rf_test_pred)/y_rf_test_pred)), 2))\n",
        "print(\"Mean Absolute Error (Σ|y-pred|/n):\", \"{:,.0f}\".format(metrics.mean_absolute_error(y_test, y_rf_test_pred)))\n",
        "print(\"Root Mean Squared Error (sqrt(Σ(y-pred)^2/n)):\", \"{:,.0f}\".format(np.sqrt(metrics.mean_squared_error(y_test, y_rf_test_pred))))\n",
        "## residuals\n",
        "residuals = y_test - y_rf_test_pred\n",
        "max_error = max(residuals) if abs(max(residuals)) > abs(min(residuals)) else min(residuals)\n",
        "max_idx = list(residuals).index(max(residuals)) if abs(max(residuals)) > abs(min(residuals)) else list(residuals).index(min(residuals))\n",
        "max_true, max_pred = y_test[max_idx], y_rf_test_pred[max_idx]\n",
        "print(\"Max Error:\", \"{:,.0f}\".format(max_error))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, the performance is similar, and actually a bit worse, than the LASSO regression. We may be able to push performance a bit via tuning, so let's try using a few more trees:"
      ],
      "metadata": {
        "id": "sYE_w4i4SzJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "house_rf = RandomForestRegressor(random_state=1,n_estimators=250)\n",
        "house_rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "-1p_frjSTP5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_rf_test_pred = house_rf.predict(X_test)\n",
        "## Kpi\n",
        "print(\"R2 (explained variance):\", round(metrics.r2_score(y_test, y_rf_test_pred), 2))\n",
        "print(\"Mean Absolute Perc Error (Σ(|y-pred|/y)/n):\", round(np.mean(np.abs((y_test-y_rf_test_pred)/y_rf_test_pred)), 2))\n",
        "print(\"Mean Absolute Error (Σ|y-pred|/n):\", \"{:,.0f}\".format(metrics.mean_absolute_error(y_test, y_rf_test_pred)))\n",
        "print(\"Root Mean Squared Error (sqrt(Σ(y-pred)^2/n)):\", \"{:,.0f}\".format(np.sqrt(metrics.mean_squared_error(y_test, y_rf_test_pred))))\n",
        "## residuals\n",
        "residuals = y_test - y_rf_test_pred\n",
        "max_error = max(residuals) if abs(max(residuals)) > abs(min(residuals)) else min(residuals)\n",
        "max_idx = list(residuals).index(max(residuals)) if abs(max(residuals)) > abs(min(residuals)) else list(residuals).index(min(residuals))\n",
        "max_true, max_pred = y_test[max_idx], y_rf_test_pred[max_idx]\n",
        "print(\"Max Error:\", \"{:,.0f}\".format(max_error))"
      ],
      "metadata": {
        "id": "L7P6ZhfgTamw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, not much better, in line with the point mentioned that random forests aren't super sensitive to tuning.\n",
        "\n",
        "Let's try..."
      ],
      "metadata": {
        "id": "YsM7mdOwTkN2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SrwOVgNTluG"
      },
      "source": [
        "### Gradient Boosting\n",
        "\n",
        "Again, let's start with default parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ2YSyicTonk"
      },
      "source": [
        "house_boost = GradientBoostingRegressor(random_state=1)\n",
        "house_boost.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And let's predict and check performance:"
      ],
      "metadata": {
        "id": "OuLOI1p-T-xW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoFfQxe6I0_G"
      },
      "source": [
        "y_boost_test_pred = house_boost.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsjKdY607kan"
      },
      "source": [
        "## Kpi\n",
        "print(\"R2 (explained variance):\", round(metrics.r2_score(y_test, y_boost_test_pred), 2))\n",
        "print(\"Mean Absolute Perc Error (Σ(|y-pred|/y)/n):\", round(np.mean(np.abs((y_test-y_boost_test_pred)/y_boost_test_pred)), 2))\n",
        "print(\"Mean Absolute Error (Σ|y-pred|/n):\", \"{:,.0f}\".format(metrics.mean_absolute_error(y_test, y_boost_test_pred)))\n",
        "print(\"Root Mean Squared Error (sqrt(Σ(y-pred)^2/n)):\", \"{:,.0f}\".format(np.sqrt(metrics.mean_squared_error(y_test, y_boost_test_pred))))\n",
        "## residuals\n",
        "residuals = y_test - y_boost_test_pred\n",
        "max_error = max(residuals) if abs(max(residuals)) > abs(min(residuals)) else min(residuals)\n",
        "max_idx = list(residuals).index(max(residuals)) if abs(max(residuals)) > abs(min(residuals)) else list(residuals).index(min(residuals))\n",
        "max_true, max_pred = y_test[max_idx], y_boost_test_pred[max_idx]\n",
        "print(\"Max Error:\", \"{:,.0f}\".format(max_error))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we actually see a bit of a performance increase in terms of MSE. Let's try tuning the model:"
      ],
      "metadata": {
        "id": "o1z-rlpVUB8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_rmse = 50000\n",
        "\n",
        "n_estimators_grid = [100, 500, 1000]\n",
        "learning_rate_grid = [0.05, 0.075, 0.1]\n",
        "\n",
        "for n_estimators in n_estimators_grid:\n",
        "  for learning_rate in learning_rate_grid:\n",
        "    # Train the GradientBoostingClassifier with the current parameters\n",
        "    house_boost = GradientBoostingRegressor(n_estimators=n_estimators, learning_rate=learning_rate, random_state=1)\n",
        "    house_boost.fit(X_train, y_train)\n",
        "\n",
        "    # Predict probabilities for the test set\n",
        "    y_boost_val = house_boost.predict(X_val)\n",
        "    rmse = np.sqrt(metrics.mean_squared_error(y_val, y_boost_val))\n",
        "    print(\"RMSE:\", rmse)\n",
        "\n",
        "\n",
        "    # Update the best AUC and parameters if the current AUC is better\n",
        "    if rmse < best_rmse:\n",
        "        best_rmse = rmse\n",
        "        best_params = {'n_estimators': n_estimators, 'learning_rate': learning_rate}\n",
        "\n",
        "print(\"Best RMSE:\", best_rmse)\n",
        "print(\"Best parameters:\", best_params)"
      ],
      "metadata": {
        "id": "bKqASt37UMeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we see something quite curious: It appears the RMSE in the validation set (around 50,000) is much larger than in the test set (around 20,000). This showcases the challenges with using a single split of our data---there may be odd observations that can affect the fit dramatically... So, it is unclear whether the guidance from the tuning exercise is helpful. However, in line with the guidance, let's try a lower learning rate (and a moderate amount more trees):"
      ],
      "metadata": {
        "id": "S8i-_gUlYSt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "house_boost = GradientBoostingRegressor(random_state=1, learning_rate=0.075, n_estimators=500)\n",
        "house_boost.fit(X_train, y_train)\n",
        "y_boost_test_pred = house_boost.predict(X_test)"
      ],
      "metadata": {
        "id": "Kcc2aphnWm0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Kpi\n",
        "print(\"R2 (explained variance):\", round(metrics.r2_score(y_test, y_boost_test_pred), 2))\n",
        "print(\"Mean Absolute Perc Error (Σ(|y-pred|/y)/n):\", round(np.mean(np.abs((y_test-y_boost_test_pred)/y_boost_test_pred)), 2))\n",
        "print(\"Mean Absolute Error (Σ|y-pred|/n):\", \"{:,.0f}\".format(metrics.mean_absolute_error(y_test, y_boost_test_pred)))\n",
        "print(\"Root Mean Squared Error (sqrt(Σ(y-pred)^2/n)):\", \"{:,.0f}\".format(np.sqrt(metrics.mean_squared_error(y_test, y_boost_test_pred))))\n",
        "## residuals\n",
        "residuals = y_test - y_boost_test_pred\n",
        "max_error = max(residuals) if abs(max(residuals)) > abs(min(residuals)) else min(residuals)\n",
        "max_idx = list(residuals).index(max(residuals)) if abs(max(residuals)) > abs(min(residuals)) else list(residuals).index(min(residuals))\n",
        "max_true, max_pred = y_test[max_idx], y_boost_test_pred[max_idx]\n",
        "print(\"Max Error:\", \"{:,.0f}\".format(max_error))"
      ],
      "metadata": {
        "id": "379dNB8oW8y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, the performance is similar..."
      ],
      "metadata": {
        "id": "uEIhxp4lZ_vt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that for now, we by default considered a quadratic criterion. We can also choose the absolute value:"
      ],
      "metadata": {
        "id": "rWQYlwEBaoDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "house_boost = GradientBoostingRegressor(random_state=1, loss = \"absolute_error\", learning_rate=0.075, n_estimators=500)\n",
        "house_boost.fit(X_train, y_train)\n",
        "y_boost_test_pred = house_boost.predict(X_test)\n",
        "## Kpi\n",
        "print(\"R2 (explained variance):\", round(metrics.r2_score(y_test, y_boost_test_pred), 2))\n",
        "print(\"Mean Absolute Perc Error (Σ(|y-pred|/y)/n):\", round(np.mean(np.abs((y_test-y_boost_test_pred)/y_boost_test_pred)), 2))\n",
        "print(\"Mean Absolute Error (Σ|y-pred|/n):\", \"{:,.0f}\".format(metrics.mean_absolute_error(y_test, y_boost_test_pred)))\n",
        "print(\"Root Mean Squared Error (sqrt(Σ(y-pred)^2/n)):\", \"{:,.0f}\".format(np.sqrt(metrics.mean_squared_error(y_test, y_boost_test_pred))))\n",
        "## residuals\n",
        "residuals = y_test - y_boost_test_pred\n",
        "max_error = max(residuals) if abs(max(residuals)) > abs(min(residuals)) else min(residuals)\n",
        "max_idx = list(residuals).index(max(residuals)) if abs(max(residuals)) > abs(min(residuals)) else list(residuals).index(min(residuals))\n",
        "max_true, max_pred = y_test[max_idx], y_boost_test_pred[max_idx]\n",
        "print(\"Max Error:\", \"{:,.0f}\".format(max_error))"
      ],
      "metadata": {
        "id": "5mxG_57NbBWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, the performance is fairly similar, but it optimizes the absolute error. In other applications, this can make a substantive difference."
      ],
      "metadata": {
        "id": "nvnXSichbui6"
      }
    }
  ]
}