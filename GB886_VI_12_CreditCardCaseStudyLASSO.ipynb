{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielbauer1979/MSDIA_PredictiveModelingAndMachineLearning/blob/main/GB886_VI_12_CreditCardCaseStudyLASSO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Credit Card Defaults -- Revisited"
      ],
      "metadata": {
        "id": "bFNuMreLe4xh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQkFLmYWqmN3"
      },
      "source": [
        "In this tutorial, we will use logistic to predict credit card default scores -- but this time we will select an appropriate model rather than using the full set of features.\n",
        "\n",
        "As a reminder, the dataset provides credit card defaults for customers in Taiwan.  We are given some demographic information ($X_1$-$X_5$), the previous history of payments ($X_6$-$X_{11}$), the amount of previous bills ($X_{12}$-$X_{17}$), and amounts of previous payments ($X_{18}$-$X_{23}$).  Finally, variable 24 is our target, whetyher there was a default in the next months.\n",
        "\n",
        "\n",
        "As always, let's start with importing the libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANNbSksYqWS3"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from sklearn.metrics import confusion_matrix, classification_report, precision_score, roc_curve, auc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And let's load and prepare the dataset (we follow the exact same steps as before):"
      ],
      "metadata": {
        "id": "okvP8ddqfGwX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70QK-AnxqWTB"
      },
      "source": [
        "!git clone https://github.com/danielbauer1979/MSDIA_PredictiveModelingAndMachineLearning.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzW2COB-qWTC"
      },
      "source": [
        "mydata = pd.read_csv('MSDIA_PredictiveModelingAndMachineLearning/GB886_IV_12_UCI_Credit_Card.csv', index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "factor = ['SEX', 'EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'default.payment.next.month']\n",
        "\n",
        "mydata['PAY_0'][mydata['PAY_0']>4] = 4\n",
        "mydata['PAY_2'][mydata['PAY_2']>4] = 4\n",
        "mydata['PAY_3'][mydata['PAY_3']>4] = 4\n",
        "mydata['PAY_4'][mydata['PAY_4']>4] = 4\n",
        "mydata['PAY_5'][mydata['PAY_5']>4] = 4\n",
        "mydata['PAY_6'][mydata['PAY_6']>4] = 4\n",
        "\n",
        "mydata_numcols = mydata.drop(columns = factor)\n",
        "mydata_faccols = mydata[factor].astype('category')\n",
        "dummies = pd.get_dummies(mydata_faccols, drop_first=True)\n",
        "mydata = pd.concat([mydata_numcols, dummies], axis = 1)\n",
        "\n",
        "mydata = mydata.rename(columns={\"default.payment.next.month_1\": \"default\"})\n",
        "\n",
        "mydata.insert(17, \"BILL_AVG\", (mydata['BILL_AMT1']+mydata['BILL_AMT2']+mydata['BILL_AMT3']+mydata['BILL_AMT4']+mydata['BILL_AMT5']+mydata['BILL_AMT6'])/6, True)\n",
        "mydata = mydata.rename(columns={\"BILL_AMT1\": \"BILL_REC\"})\n",
        "del mydata['BILL_AMT2']\n",
        "del mydata['BILL_AMT3']\n",
        "del mydata['BILL_AMT4']\n",
        "del mydata['BILL_AMT5']\n",
        "del mydata['BILL_AMT6']"
      ],
      "metadata": {
        "id": "ZAwjAtXxgJ9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictive Modeling: Baseline Logistic Regression"
      ],
      "metadata": {
        "id": "Xwm41PjahXf0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's again run our baseline logistic regression model:\n"
      ],
      "metadata": {
        "id": "e80dFeKijLfn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK8HBxrBqWTI"
      },
      "source": [
        "y = mydata['default']\n",
        "X = mydata.drop(columns = ['default'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_mod = sm.Logit(y, sm.add_constant(X).astype(float))\n",
        "logistic_mod = logistic_mod.fit(maxiter = 10000)\n",
        "print(logistic_mod.summary())"
      ],
      "metadata": {
        "id": "yJRgok_IQFBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And let's check the predictions via the confusion matrix:"
      ],
      "metadata": {
        "id": "PxNquZnljYn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p_x = logistic_mod.predict()\n",
        "y_hat = (p_x > 0.5)\n",
        "\n",
        "conf_mat = pd.crosstab(y, y_hat, rownames=['Actual Defaults'], colnames=['Predicted Defualts'])\n",
        "# Add row and column sums\n",
        "conf_mat.loc['Column_Total']= conf_mat.sum(numeric_only=True, axis=0)\n",
        "conf_mat.loc[:,'Row_Total'] = conf_mat.sum(numeric_only=True, axis=1)\n",
        "print(conf_mat)"
      ],
      "metadata": {
        "id": "b-CbR92JxFfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "And the **ROC curve**:"
      ],
      "metadata": {
        "id": "4pC5K5zNjbXe"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIY4iAiwqWTL"
      },
      "source": [
        "fpr, tpr, threshold = roc_curve(y, p_x)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictive Modeling: Forward Selection\n",
        "\n",
        "Now, instead of using all features, let's run a forward selection procedure using AIC:\n"
      ],
      "metadata": {
        "id": "tnAJTmNsk-j1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variables = X.columns.tolist()\n",
        "selected_variables = []\n",
        "best_aic = float('inf')\n",
        "\n",
        "while variables:\n",
        "    remaining_variables = list(set(variables) - set(selected_variables))\n",
        "    candidate_models = []\n",
        "\n",
        "    for var in remaining_variables:\n",
        "        candidate_vars = selected_variables + [var]\n",
        "        X_candidate = sm.add_constant(X[candidate_vars]).astype(float)\n",
        "        model = sm.Logit(y, X_candidate).fit(disp=0, maxiter=10000)\n",
        "        candidate_models.append((model, model.aic))\n",
        "\n",
        "    best_model, current_aic = min(candidate_models, key=lambda x: x[1])\n",
        "\n",
        "    if current_aic < best_aic:\n",
        "        best_aic = current_aic\n",
        "        selected_variables.append(best_model.params.index[-1])  # Add the variable that improved AIC\n",
        "    else:\n",
        "        break  # Stop if AIC starts increasing\n",
        "\n",
        "print(\"Selected Variables:\", selected_variables)\n",
        "print(best_model.summary())\n"
      ],
      "metadata": {
        "id": "ldh99OUfhqFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So it turns out that we dropped quite a few variables: The original model had 54 features, the selected model has 35!\n",
        "\n",
        "Let's see how the predictions compare:"
      ],
      "metadata": {
        "id": "PuuJQy5Mk_R5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict probabilities using the best model\n",
        "p_x_best = best_model.predict()\n",
        "\n",
        "# Classify predictions based on a 0.5 cutoff\n",
        "y_hat_best = (p_x_best > 0.5)\n",
        "\n",
        "# Create confusion matrix\n",
        "conf_mat_best = pd.crosstab(y, y_hat_best, rownames=['Actual Defaults'], colnames=['Predicted Defaults'])\n",
        "\n",
        "# Add row and column sums\n",
        "conf_mat_best.loc['Column_Total'] = conf_mat_best.sum(numeric_only=True, axis=0)\n",
        "conf_mat_best.loc[:, 'Row_Total'] = conf_mat_best.sum(numeric_only=True, axis=1)\n",
        "\n",
        "print(conf_mat_best)\n",
        "\n",
        "# Generate ROC curve\n",
        "fpr_best, tpr_best, threshold_best = roc_curve(y, p_x_best)\n",
        "roc_auc_best = auc(fpr_best, tpr_best)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic (Best Model)')\n",
        "plt.plot(fpr_best, tpr_best, 'b', label='AUC = %0.2f' % roc_auc_best)\n",
        "plt.legend(loc='lower right')\n",
        "plt.plot([0, 1], [0, 1], 'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "K92Rec4ijLEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the model does not perform any better---BUT WE SHOULD ALSO NOT EXPECT IT TO!! In fact, the confusion matrix and the AUC above were cast within the training sample, so they are arguably overly optimistic. Recall, in sample, we will always choose the most complex model.\n",
        "\n",
        "In fact, it is suprising how well the model performs in relation given that it has substantially fewer features: The AUC seems unchanged, and the confusion matrix only has slightly more false negatives and false positives.\n",
        "\n",
        "Out of sample, we should expect to the reduced model to perform better!"
      ],
      "metadata": {
        "id": "5_agPcBglX7f"
      }
    }
  ]
}