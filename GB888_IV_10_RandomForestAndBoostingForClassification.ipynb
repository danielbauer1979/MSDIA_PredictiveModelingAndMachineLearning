{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielbauer1979/MSDIA_PredictiveModelingAndMachineLearning/blob/main/GB888_IV_10_RandomForestAndBoostingForClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest And Boosting For Classification\n",
        "\n",
        "\n",
        "In this tutorial, we then use random forests and boosted trees in our case study example for the Caravan Insurance purchases, analyzing whether they can improve on the learners considered so far.\n",
        "\n",
        "As usually, let's start with loading the relevant libaries."
      ],
      "metadata": {
        "id": "_Dgf3D6YiA0C"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vCC-SQb7VRR"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.api as sm\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import mean_squared_error,confusion_matrix, classification_report, roc_curve, auc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Case Study: Caravan Insurance Purchases\n",
        "\n",
        "Let's go back to the `Caravan` insurance data:"
      ],
      "metadata": {
        "id": "zNnvu0I48wYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/danielbauer1979/MSDIA_PredictiveModelingAndMachineLearning.git"
      ],
      "metadata": {
        "id": "Gb1EdVnT8xy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Caravan = pd.read_csv('MSDIA_PredictiveModelingAndMachineLearning/GB888_III_7_CaravanData.csv', index_col=0)"
      ],
      "metadata": {
        "id": "zhmtJl7D82OM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's split the dataset, using the same approach as we did in the previous module:"
      ],
      "metadata": {
        "id": "v2IifQXX84Rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Caravan.Purchase = (Caravan.Purchase=='Yes')\n",
        "train, test = train_test_split(Caravan, test_size=0.25, random_state=1)\n",
        "\n",
        "X = train.drop(['Purchase'], axis=1)\n",
        "y = train['Purchase']\n",
        "Xtest = test.drop(['Purchase'], axis=1)\n",
        "ytest = test['Purchase']"
      ],
      "metadata": {
        "id": "YmQbQjam9BWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To recall, we previously considered a logistic regression model. It produced an AUC of .71 but did not determine a single true positive for a 50% cutoff. We also considered a pruned tree which produced an AUC of .72, which was able to determine a few true positives!"
      ],
      "metadata": {
        "id": "j3cAUCS6tAhb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Random Forest"
      ],
      "metadata": {
        "id": "II5Xb1RT-a-l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start with a random forest (with default parameters, so no tuning for now):"
      ],
      "metadata": {
        "id": "SxOEFk5Q_tGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(random_state=1)\n",
        "rf.fit(X, y)"
      ],
      "metadata": {
        "id": "aOXgXBgU-dd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To appraise what features matter, let's consider feature importance scores:"
      ],
      "metadata": {
        "id": "OP9MaM0h_wFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Importance_ = pd.DataFrame({'Importance':rf.feature_importances_*100}, index=X.columns)\n",
        "Importance = Importance_.sort_values('Importance', axis=0, ascending=False)[0:20]\n",
        "Importance.plot(kind='barh', color='b', ).invert_yaxis()\n",
        "plt.xlabel('Variable Importance')\n",
        "plt.gca().legend_ = None"
      ],
      "metadata": {
        "id": "BN8FUuQ1-hay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Let's look at the predictions:"
      ],
      "metadata": {
        "id": "f6t_rsaH_zsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_rf = rf.predict_proba(Xtest)\n",
        "pred_rf = pred_rf[:,1]"
      ],
      "metadata": {
        "id": "1Ff_lxHt-un9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And ROC curve/AUC:"
      ],
      "metadata": {
        "id": "y01n0qIH_5mA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, threshold = roc_curve(ytest, pred_rf)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UDlvRmp7-yaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.5\n",
        "y_pred_class = (pred_rf > threshold).astype(int)\n",
        "\n",
        "conf_matrix = confusion_matrix(ytest, y_pred_class)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "id": "CoINzRaBvsbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So not quite the same performance as the pruned (!) tree or the logistic regression model. Let's try a second random forest with alternate parameters, a few more trees and 45 features sampled per tree:"
      ],
      "metadata": {
        "id": "Ri3NA_kp_7fY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=400, max_features=45, random_state=1)\n",
        "rf.fit(X, y)\n",
        "pred_rf = rf.predict_proba(Xtest)\n",
        "pred_rf = pred_rf[:,1]"
      ],
      "metadata": {
        "id": "0hRXDgdSwIdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the AUC:"
      ],
      "metadata": {
        "id": "oYO1SqqOyXJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, threshold = roc_curve(ytest, pred_rf)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J9dI8vCaxUGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So it gets a little better but not much..."
      ],
      "metadata": {
        "id": "oXCC2F4Jybsd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Boosting"
      ],
      "metadata": {
        "id": "lvzknaCb96qh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's run a gradieny boosting model, again with the standard parameters:"
      ],
      "metadata": {
        "id": "xlQu_oRg_V6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boost = GradientBoostingClassifier(random_state=1)\n",
        "boost.fit(X, y)"
      ],
      "metadata": {
        "id": "_PX2C-Kw-Hmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To appraise what features matter, let's consider feature importance scores:"
      ],
      "metadata": {
        "id": "w9UBr7X8_YPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance = boost.feature_importances_*100\n",
        "rel_imp = pd.Series(feature_importance, index=X.columns).sort_values(ascending=False, inplace=False)\n",
        "rel_imp = rel_imp[0:20]\n",
        "print(rel_imp)\n",
        "rel_imp.plot(kind='barh', color='b', ).invert_yaxis()\n",
        "plt.xlabel('Variable Importance')"
      ],
      "metadata": {
        "id": "jp4Bjexf-NRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So here the important features are quite different.\n",
        "\n",
        "The predictions are:"
      ],
      "metadata": {
        "id": "EyovqtSR_hqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_boost = boost.predict_proba(Xtest)\n",
        "pred_boost = pred_boost[:,1]"
      ],
      "metadata": {
        "id": "VddIufzC-Voe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resulting in the following ROC curve and AUC:"
      ],
      "metadata": {
        "id": "kKsmeqdN_l-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, threshold = roc_curve(ytest, pred_boost)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Lzc8IX1J-aKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, the performance improves quite a bit, and we are also beating the pruned tree and the logistic regression model.\n",
        "\n",
        "Let's decrease the learning rate and use a few more trees:"
      ],
      "metadata": {
        "id": "5nEEFBgyzD8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boost = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.001,random_state=1)\n",
        "boost.fit(X, y)\n",
        "\n",
        "pred_boost = boost.predict_proba(Xtest)\n",
        "pred_boost = pred_boost[:,1]\n",
        "\n",
        "fpr, tpr, threshold = roc_curve(ytest, pred_boost)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Um1Cmavyyv2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the performance improves a little. Let's look at the confusion matrix:"
      ],
      "metadata": {
        "id": "9pJcBvl9QHX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.2 # 0.5 generates only zeros\n",
        "y_pred_class = (pred_boost > threshold).astype(int)\n",
        "\n",
        "conf_matrix = confusion_matrix(ytest, y_pred_class)\n",
        "print(\"Confusion Matrix:\")\n",
        "conf_matrix"
      ],
      "metadata": {
        "id": "sKC-IpPZ0mtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ADA Boosting\n",
        "\n",
        "Let's finally look at the ADA boost"
      ],
      "metadata": {
        "id": "4tfsqJ250nC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ada = AdaBoostClassifier(random_state=1)  # Adjust n_estimators as needed\n",
        "ada.fit(X, y)"
      ],
      "metadata": {
        "id": "Ak1qy0znUeoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With predictions:"
      ],
      "metadata": {
        "id": "_Bf2ozIx1zHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_ada = ada.predict_proba(Xtest)[:, 1]"
      ],
      "metadata": {
        "id": "-xQEnM3e1XvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And let's generate an ROC curve:"
      ],
      "metadata": {
        "id": "Gdbjbqtm14PU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, threshold = roc_curve(ytest, pred_ada)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.title('Receiver Operating Characteristic (AdaBoost)')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CxCkT4Jd13Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So again a pretty decent performance with an AUC of .75."
      ],
      "metadata": {
        "id": "otjw2MJN1_iJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's also go with a lower learning rate but more trees:"
      ],
      "metadata": {
        "id": "fcqFGxbW2IBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ada = AdaBoostClassifier(n_estimators=1000,learning_rate=0.04,random_state=1)  # Adjust n_estimators as needed\n",
        "ada.fit(X, y)\n",
        "\n",
        "# Predictions\n",
        "pred_ada = ada.predict_proba(Xtest)[:, 1]  # Probability of positive class\n",
        "\n",
        "# ROC curve and AUC\n",
        "fpr, tpr, threshold = roc_curve(ytest, pred_ada)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.title('Receiver Operating Characteristic (AdaBoost)')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HbSLFa6S1aoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TNLugDmh2toy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So not really an improvement here."
      ],
      "metadata": {
        "id": "DD5QBNMC2W4A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of course, we could tune by more systematically going through the hyper-parameters, but we observe that also the standard parameters produce decent models."
      ],
      "metadata": {
        "id": "a-bMgN4O2bTX"
      }
    }
  ]
}