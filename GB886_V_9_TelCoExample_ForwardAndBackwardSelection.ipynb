{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUC2G2ws46yxXxAmz+WWhR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielbauer1979/MSDIA_PredictiveModelingAndMachineLearning/blob/main/GB886_V_9_TelCoExample_ForwardAndBackwardSelection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Selection: Telecom Work Measurement Study\n",
        "\n",
        "To introduce and discuss how model selection is relevant, we consider an example from a [Telecom Work Measurement Study](http://www.statsci.org/data/oz/telecom.html). The data originates from study for a telecom company (we are only using an excerpt). According to the website, “the purpose of the study was to model the total hours worked in a section of Telecom in terms of the counts of various tasks. It was hoped that such a model could be used to predict hours worked and hence staffing requirements in changing circumstances. The number of hours worked by employees in a fault reporting centre were recorded, together with the number of faults of each type which were recorded. Employees often work on a flexitime system which allows them to build up time and to leave early every second Friday.”\n",
        "\n",
        "We will use it to showcase that the most complex model is not necessarily the best. Specifically, we will run different models (i.e., including different sets of features) and compare them.\n",
        "\n",
        "## Preliminaries\n",
        "\n",
        "As usually, we start by loading some of the packages we will use and the data:"
      ],
      "metadata": {
        "id": "kTwZI0SwiAE5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IOkuUgBh9v7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And let's load our data:"
      ],
      "metadata": {
        "id": "-emH9vLPiGHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/danielbauer1979/MSDIA_PredictiveModelingAndMachineLearning.git"
      ],
      "metadata": {
        "id": "uXLnk1rqiypy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('MSDIA_PredictiveModelingAndMachineLearning/GB886_V_4_tel_base.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "id": "u336jSiXi4CK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our target/label variable $y$ is 'Hours' (hours worked on a given day), and we have features relating to the activities performed (e.g., Number of service orders of type A/B/C given by SOA/SOB/SOC; number of hotlines given by Hot) and the characteristics of the day (e.g., what day of the week is it)."
      ],
      "metadata": {
        "id": "XpBUGIVy2UHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at a few variables:"
      ],
      "metadata": {
        "id": "AygXvXqT1lDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(data['Hot'], data['Hours'])\n",
        "plt.xlabel('Hot')\n",
        "plt.ylabel('Hours')\n",
        "\n",
        "# Add a trendline\n",
        "X = sm.add_constant(data['Hot'])\n",
        "model = sm.OLS(data['Hours'], X).fit()\n",
        "plt.plot(data['Hot'], model.predict(X), color='red')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HGALwglqF6Ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So it seems like hours worked are increasing in Hot."
      ],
      "metadata": {
        "id": "6y5_I97g4JZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ys = [data['Hours'][data['Tuesday'] == 1],data['Hours'][data['Wednesday'] == 1],\n",
        "               data['Hours'][data['Thursday'] == 1],\n",
        "               data['Hours'][data['Friday'] == 1]]\n",
        "plt.boxplot(ys, labels=['Tuesday','Wednesday','Thursday','Friday'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "m3EFOK115ThF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And it seems like fewer hours are worked on Friday!"
      ],
      "metadata": {
        "id": "FDu-cd525m7A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Regression models\n",
        "\n",
        "Let's start running our linear regression models. In line with our approach so far, let's run the \"full\" model including all the features\""
      ],
      "metadata": {
        "id": "_zq5d-BQ50pE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start running regressions, and let's start with the \"full\" model."
      ],
      "metadata": {
        "id": "xQ8ub-dCjRQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = data['Hours']\n",
        "X = data.drop(columns=['Hours'])\n",
        "X = sm.add_constant(X)\n",
        "model_full = sm.OLS(y, X).fit()\n",
        "model_full.summary()"
      ],
      "metadata": {
        "id": "WYYYv4EtjTOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So in line with our visualizations above, Hot carries a positive coefficients and Friday carries a negative coefficient. However, many of the coefficients are not significant. For instance, the day dummies other than Friday don't seem to be significant. Let's drop these days:"
      ],
      "metadata": {
        "id": "bjAcqsoa7CTK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So it looks like only Friday really matters, so let's drop the other days."
      ],
      "metadata": {
        "id": "SBdAA60eJROK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(columns=['Hours','Tuesday','Wednesday','Thursday'])\n",
        "X = sm.add_constant(X)\n",
        "model_reduced_days = sm.OLS(y, X).fit()\n",
        "model_reduced_days.summary()"
      ],
      "metadata": {
        "id": "52iSkzRGjkiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's also look at a reduced model with just four variables that seem likely different than zero (their t-statistics are reasonably high):"
      ],
      "metadata": {
        "id": "SXqmpF22JiuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[['RWT','SOA','Hot','Friday']]\n",
        "X = sm.add_constant(X)\n",
        "model_reduced = sm.OLS(y, X).fit()\n",
        "model_reduced.summary()"
      ],
      "metadata": {
        "id": "xmT9acCYjqG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's fun a model with only Friday as the feature:"
      ],
      "metadata": {
        "id": "yN_FOqqg-7jC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[['Friday']]\n",
        "X = sm.add_constant(X)\n",
        "model_simplest = sm.OLS(y, X).fit()\n",
        "model_simplest.summary()"
      ],
      "metadata": {
        "id": "2D-5INmI-x1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compare the three models. We will do it two different ways: On the $x$-axis, let's go from simple to more complex models (with the \"full\" model being the most complex). On the $y$-axis, we will look first at the **Mean-squared-Error** (average of the squared errors: $\\frac{1}{N}\\sum_{i=1}^N (y_i - \\hat{y}_i)^2$) and then at the **R-squared**.\n",
        "\n",
        "Let's define the components:"
      ],
      "metadata": {
        "id": "UeD5_5yf-FP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse_simplest = np.average(model_simplest.resid ** 2)\n",
        "mse_reduced = np.average(model_reduced.resid ** 2)\n",
        "mse_reduced_days = np.average(model_reduced_days.resid ** 2)\n",
        "mse_full = np.average(model_full.resid ** 2)\n",
        "\n",
        "model_names = ['Simplest','Reduced', 'Reduced Days', 'Full']\n",
        "mse_values = [mse_simplest,mse_reduced, mse_reduced_days, mse_full]\n",
        "rsquared_values = [model_simplest.rsquared, model_reduced.rsquared, model_reduced_days.rsquared, model_full.rsquared]"
      ],
      "metadata": {
        "id": "0uoknlJg_Zs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And plot the two:"
      ],
      "metadata": {
        "id": "8Yv0-5HGABac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Plot the MSE values on the first subplot\n",
        "axs[0].plot(model_names, mse_values, marker='o')\n",
        "axs[0].set_xlabel('Model')\n",
        "axs[0].set_ylabel('Average of Squared Errors (MSE)')\n",
        "axs[0].set_title('Comparison of Model MSE')\n",
        "\n",
        "# Plot the R-squared values on the second subplot\n",
        "axs[1].plot(model_names, rsquared_values, marker='o')\n",
        "axs[1].set_xlabel('Model')\n",
        "axs[1].set_ylabel('R-squared')\n",
        "axs[1].set_title('Comparison of Model R-squared')\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "p2pWxTUB92uD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, it appears that the most complex model---the model \"Full\"---seems to produce the lowest mean-squared error and the highest R-squared. So the **most complex model appears to be the best model**."
      ],
      "metadata": {
        "id": "PCdrcLEPAD9c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison based on New, Unseen Data\n",
        "\n",
        "Let's follow the outlined strategy and compare the model based on previously unseen data:"
      ],
      "metadata": {
        "id": "0Xrn7gDuAiK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_addtl = pd.read_csv('MSDIA_PredictiveModelingAndMachineLearning/GB886_V_4_tel_addtl.csv')\n",
        "data_addtl.head()"
      ],
      "metadata": {
        "id": "mvlDDuw3AmWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's generate predictions for our four models based on this new dataset:"
      ],
      "metadata": {
        "id": "11sSubxIESs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature matrices for the four models\n",
        "X_new = data_addtl.drop(columns=['Hours'])\n",
        "X_new = sm.add_constant(X_new)\n",
        "X_new_simplest = X_new[['Friday']]\n",
        "X_new_simplest = sm.add_constant(X_new_simplest)\n",
        "X_new_reduced = X_new[['RWT','SOA','Hot','Friday']]\n",
        "X_new_reduced = sm.add_constant(X_new_reduced)\n",
        "X_new_reduced_days = X_new.drop(columns=['Tuesday','Wednesday','Thursday'])\n",
        "\n",
        "# Predict using the four models\n",
        "predictions_full = model_full.predict(X_new)\n",
        "predictions_simplest = model_simplest.predict(X_new_simplest)\n",
        "predictions_reduced = model_reduced.predict(X_new_reduced)\n",
        "predictions_reduced_days = model_reduced_days.predict(X_new_reduced_days)"
      ],
      "metadata": {
        "id": "_WNnfVEwEhO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And let's regenerate the plots from above using the new predictions:"
      ],
      "metadata": {
        "id": "XQ5BmFd5E8Ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MSE for the new predictions\n",
        "y_true = data_addtl['Hours']\n",
        "mse_simplest_new = np.average((y_true - predictions_simplest) ** 2)\n",
        "mse_reduced_new = np.average((y_true - predictions_reduced) ** 2)\n",
        "mse_reduced_days_new = np.average((y_true - predictions_reduced_days) ** 2)\n",
        "mse_full_new = np.average((y_true - predictions_full) ** 2)\n",
        "\n",
        "# Calculate R-squared for the new predictions\n",
        "sse_simplest_new = np.sum((y_true - predictions_simplest) ** 2)\n",
        "sse_reduced_new = np.sum((y_true - predictions_reduced) ** 2)\n",
        "sse_reduced_days_new = np.sum((y_true - predictions_reduced_days) ** 2)\n",
        "sse_full_new = np.sum((y_true - predictions_full) ** 2)\n",
        "\n",
        "sst_new = np.sum((y_true - np.mean(y_true)) ** 2)\n",
        "\n",
        "rsquared_simplest_new = 1 - (sse_simplest_new / sst_new)\n",
        "rsquared_reduced_new = 1 - (sse_reduced_new / sst_new)\n",
        "rsquared_reduced_days_new = 1 - (sse_reduced_days_new / sst_new)\n",
        "rsquared_full_new = 1 - (sse_full_new / sst_new)\n",
        "\n",
        "# Plot the MSE and R-squared values for the new predictions\n",
        "mse_values_new = [mse_simplest_new, mse_reduced_new, mse_reduced_days_new, mse_full_new]\n",
        "rsquared_values_new = [rsquared_simplest_new, rsquared_reduced_new, rsquared_reduced_days_new, rsquared_full_new]\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Plot the MSE values on the first subplot\n",
        "axs[0].plot(model_names, mse_values_new, marker='o')\n",
        "axs[0].set_xlabel('Model')\n",
        "axs[0].set_ylabel('Average of Squared Errors (MSE)')\n",
        "axs[0].set_title('Comparison of Model MSE (New Data)')\n",
        "\n",
        "# Plot the R-squared values on the second subplot\n",
        "axs[1].plot(model_names, rsquared_values_new, marker='o')\n",
        "axs[1].set_xlabel('Model')\n",
        "axs[1].set_ylabel('R-squared')\n",
        "axs[1].set_title('Comparison of Model R-squared (New Data)')\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EoCZMZsGAyRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, clearly, the situation changes. The most complex model (\"Full\") is no longer the best model. Indeed, it turns out that the \"Reduced Days\" model produces the smallest MSE and the highest R-squared.\n",
        "\n",
        "Notice that since typically we are predicting for previously unseen data, this perspective is the more relevant one. Hence, **generally, the most complex model is NOT the best model**."
      ],
      "metadata": {
        "id": "K2eeLxd7FPGb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ANOVA\n",
        "\n",
        "Let's compare the models based on an ANOVA. The advantage is that we can use the full dataset!"
      ],
      "metadata": {
        "id": "Irj2QHj-Haho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_combined = pd.concat([data, data_addtl], ignore_index=True)\n",
        "\n",
        "# Run the four models on the combined dataset\n",
        "y_combined = data_combined['Hours']\n",
        "X_combined = data_combined.drop(columns=['Hours'])\n",
        "X_combined = sm.add_constant(X_combined)\n",
        "model_full_combined = sm.OLS(y_combined, X_combined).fit()\n",
        "\n",
        "X_combined_reduced_days = data_combined.drop(columns=['Hours','Tuesday','Wednesday','Thursday'])\n",
        "X_combined_reduced_days = sm.add_constant(X_combined_reduced_days)\n",
        "model_reduced_days_combined = sm.OLS(y_combined, X_combined_reduced_days).fit()\n",
        "\n",
        "X_combined_reduced = data_combined[['RWT','SOA','Hot','Friday']]\n",
        "X_combined_reduced = sm.add_constant(X_combined_reduced)\n",
        "model_reduced_combined = sm.OLS(y_combined, X_combined_reduced).fit()\n",
        "\n",
        "X_combined_simplest = data_combined[['Friday']]\n",
        "X_combined_simplest = sm.add_constant(X_combined_simplest)\n",
        "model_simplest_combined = sm.OLS(y_combined, X_combined_simplest).fit()"
      ],
      "metadata": {
        "id": "hfsT439BBbJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.anova import anova_lm\n",
        "anova_results = anova_lm(model_simplest_combined, model_reduced_combined, model_reduced_days_combined, model_full_combined)\n",
        "print(anova_results)"
      ],
      "metadata": {
        "id": "Jk9bALBjHqcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, again, there is no evidence that the more complex model 4 is superior to the reduced days model 3 (bottom line). However, on this case there is also no evidence that the more complex model 3 is superior to the reduced model (line 2). However, the reduced model seems superior to the simplest model (line 1): The F statistics is fairly large and the p-value very small.\n",
        "\n",
        "So, the ANOVA guidance is different: **The best model is the reduced model**! This emphasizes one problem with the \"new data\" approach above: It really depends on the speciifc sample we are looking at.\n",
        "\n",
        "However, this begs the question of whether any of our four considered models are best? Are there approaches to more strategically pick a suitable model / set of features?\n"
      ],
      "metadata": {
        "id": "7Nb5IxlxIAjG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Selection\n",
        "\n",
        "To select a suitable model, we will use *forward* and *backward selection*:\n",
        "\n",
        "* **Forward selection**: Add features one-by-one, where on each step starting from the constant model we add the feature that increases the fit (as e.g. measured by R-squared or AIC) the most. We then use AIC across models with a different number of features to select the model at the *sweet spot*.\n",
        "\n",
        "* **Backward selection**: Drop features one-by-one, where on each step starting from the full model we drop the feature that decreases the fit the least (as e.g. measured by R-squared or AIC). We then use AIC across models with a different number of features to select the model at the *sweet spot*.\n",
        "\n",
        "'Statsmodels' does not have an automatic procedure, so we need to code this up ourselves (although the AI functionality of Colab helps :-)\n",
        "\n",
        "### Forward Selection\n",
        "\n",
        "Let's start with forward selection:"
      ],
      "metadata": {
        "id": "nyLLtuliA2jI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "remaining_features = list(X_combined.columns[1:])  # Exclude the constant term\n",
        "selected_features = []\n",
        "model_sequence = []\n",
        "aic_values = []\n",
        "\n",
        "while remaining_features:\n",
        "    best_aic = float('inf')\n",
        "    best_feature = None\n",
        "    best_model = None\n",
        "\n",
        "    for feature in remaining_features:\n",
        "        candidate_features = selected_features + [feature]\n",
        "        X_candidate = X_combined[candidate_features]\n",
        "        X_candidate = sm.add_constant(X_candidate)\n",
        "        candidate_model = sm.OLS(y_combined, X_candidate).fit()\n",
        "        candidate_aic = candidate_model.aic\n",
        "\n",
        "        if candidate_aic < best_aic:\n",
        "            best_aic = candidate_aic\n",
        "            best_feature = feature\n",
        "            best_model = candidate_model\n",
        "\n",
        "    selected_features.append(best_feature)\n",
        "    remaining_features.remove(best_feature)\n",
        "    model_sequence.append(best_model)\n",
        "    aic_values.append(best_aic)\n",
        "\n",
        "# Plot AIC values against number of features\n",
        "plt.plot(range(1, len(aic_values) + 1), aic_values, marker='o')\n",
        "plt.xlabel('Number of Features')\n",
        "plt.ylabel('AIC')\n",
        "plt.title('Forward Selection Based on AIC')\n",
        "plt.show()\n",
        "\n",
        "# Find the model with the lowest AIC\n",
        "best_model_index = np.argmin(aic_values)\n",
        "best_model = model_sequence[best_model_index]\n",
        "\n",
        "# Print the summary of the best model\n",
        "print(best_model.summary())\n"
      ],
      "metadata": {
        "id": "RtrD-SL2BV_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, we clearly see the U-shape in the complexity-AIC plot. The *sweet spot* is a model with five features, which is similar to our intuitively selected model above but not identical.\n",
        "\n",
        "### Backward Selection\n",
        "\n",
        "Let's also look at a backward-selected model:"
      ],
      "metadata": {
        "id": "w5AsuPfHOS-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "remaining_features = list(X_combined.columns[1:])\n",
        "selected_features = remaining_features.copy()\n",
        "model_sequence = []\n",
        "aic_values = []\n",
        "\n",
        "while remaining_features:\n",
        "    best_aic = float('inf')\n",
        "    worst_feature = None\n",
        "    best_model = None\n",
        "\n",
        "    X_current = X_combined[selected_features]\n",
        "    X_current = sm.add_constant(X_current)\n",
        "    current_model = sm.OLS(y_combined, X_current).fit()\n",
        "    current_aic = current_model.aic\n",
        "\n",
        "    for feature in remaining_features:\n",
        "        candidate_features = selected_features.copy()\n",
        "        candidate_features.remove(feature)\n",
        "\n",
        "        X_candidate = X_combined[candidate_features]\n",
        "        X_candidate = sm.add_constant(X_candidate)\n",
        "        candidate_model = sm.OLS(y_combined, X_candidate).fit()\n",
        "        candidate_aic = candidate_model.aic\n",
        "\n",
        "        if candidate_aic < best_aic:\n",
        "            best_aic = candidate_aic\n",
        "            worst_feature = feature\n",
        "            best_model = candidate_model\n",
        "\n",
        "    if best_aic >= current_aic:\n",
        "        break  # Stop if removing any feature increases AIC\n",
        "\n",
        "    selected_features.remove(worst_feature)\n",
        "    remaining_features.remove(worst_feature)\n",
        "    model_sequence.append(best_model)\n",
        "    aic_values.append(best_aic)\n",
        "\n",
        "# The last model in the sequence is the best one\n",
        "best_model = model_sequence[-1]\n",
        "print(best_model.summary().tables[1])\n"
      ],
      "metadata": {
        "id": "5tYfnOEfF9As"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, it turns out that we end up at the identical models based on Forward and Backward selection. However, this doesn't need to be the case!"
      ],
      "metadata": {
        "id": "DPAoC5p8OuVq"
      }
    }
  ]
}