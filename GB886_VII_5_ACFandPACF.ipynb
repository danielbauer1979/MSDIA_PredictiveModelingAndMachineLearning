{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcQUFJpfxwwsdkXKY5IVcS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielbauer1979/MSDIA_PredictiveModelingAndMachineLearning/blob/main/GB886_VII_5_ACFandPACF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Univariate Time Series\n",
        "\n",
        "This codebook goes through a few time series examples to showcase basics of univariate time series modeling for generating forecasts. We first look at some basic examples where we carry the steps out manually. We then show how packages and particularly Meta's Prophet can automate the analysis.\n"
      ],
      "metadata": {
        "id": "eHzhhWxB-V0Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As usually, let's load relevant libraries where we rely on time series functionality in statsmodels for our analysis"
      ],
      "metadata": {
        "id": "ZsyJD5FgCLpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Time series functionality\n",
        "from statsmodels.tsa.stattools import adfuller #ADF test for stationarity\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.tsa.arima.model import ARIMA"
      ],
      "metadata": {
        "id": "jPbPVkBbrYXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Two Examples\n",
        "\n",
        "We will go through two introductory examples to demonstrate different types of time series: We look at the S&P500 stock index (daily observations) as one example, and an example of retail sales (monthly observations) as a second example.\n",
        "\n",
        "### Retail Sales Data\n",
        "\n",
        "Let's load the data:"
      ],
      "metadata": {
        "id": "aMSzijK4C7TH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bz-E_E6MqM_J"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/danielbauer1979/MSDIA_PredictiveModelingAndMachineLearning.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dat_sales = pd.read_csv('MSDIA_PredictiveModelingAndMachineLearning/GB886_VII_3_RetailSales.csv')\n",
        "dat_sales.head()"
      ],
      "metadata": {
        "id": "qBuKt_rzrNe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data goes from January 1992 (index zero) to May 2016 (last index). Let's plot it:"
      ],
      "metadata": {
        "id": "40yea-btGwNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(dat_sales)\n",
        "plt.title('Retail Sales')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d23mEVuGw9vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is from **visual inspection** [link text](https://)evident that there is seasonality---the same pattern seems to occur over and over again. This is no suprise for retail sales (increased sales around the holidays, say), so our intuition is also helpful. Furthermore, there seems to be a time trend (the series trends upwards).\n",
        "\n",
        "So, to remove the trend, we use the \"decomposition\" functionality in statsmodels:"
      ],
      "metadata": {
        "id": "S4oAze5kHCh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform seasonal decomposition\n",
        "result = seasonal_decompose(dat_sales, model='additive', period=12)\n",
        "\n",
        "# Plot the trend component\n",
        "plt.plot(result.trend)\n",
        "plt.title('Trend Component of Retail Sales')\n",
        "plt.show()\n",
        "\n",
        "#Plot the seasonal component\n",
        "plt.plot(result.seasonal)\n",
        "plt.title('Seasonal Component of Retail Sales')\n",
        "plt.show()\n",
        "\n",
        "# Plot the residual component\n",
        "plt.plot(result.resid)\n",
        "plt.title('Residual Component of Retail Sales')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m9jwr21PtmC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We notice the clear trend and the seasonal pattern (which keeps on repeating). Let's check whether the residual is stationary using the *Augmented Dickey Fuller (ADF) test*, where the Null hypothesis is *non-stationarity*---so, if the p-value is small and we reject, there is evidence for stationarity:"
      ],
      "metadata": {
        "id": "GRzs5JhnHzcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_adf = adfuller(result.resid.dropna())\n",
        "print('ADF Statistic: %f' % result_adf[0])\n",
        "print('p-value: %f' % result_adf[1])\n",
        "print('Critical Values:')\n",
        "for key, value in result_adf[4].items():\n",
        "\tprint('\\t%s: %.3f' % (key, value))\n"
      ],
      "metadata": {
        "id": "yeIK0_Tau0FE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, it appears that the ADF test rejects, so it seems after removing trend and seasonality, the data appears stationary!"
      ],
      "metadata": {
        "id": "UD1uD930KLdm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's generate the autocorrelation function (ACF) and the partial autocorrelation function (PACF). As reminder, under the Box-Jenkins approach, inpsection of the ACF and the PACF are key to modeling the stationary part."
      ],
      "metadata": {
        "id": "T8SjmtuD2cVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_acf(result.resid.dropna(), lags=20)\n",
        "plt.title('ACF of Residuals')\n",
        "plt.show()\n",
        "\n",
        "plot_pacf(result.resid.dropna(), lags=20)\n",
        "plt.title('PACF of Residuals')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "njkF1mtwef08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, we see some significant spikes in both the ACF and the PACF until lag 12. the spikes in the PACF seem more subsantive. There are several models that may be possible. We could opt for an ARMA(12,12), which is appropriate for decays after 12 lags on both ACF and PACF. Another option may be an AR(12) because we see significant spikes in the PACF.\n",
        "\n",
        "Let's check both options:"
      ],
      "metadata": {
        "id": "3pm9-lIF3Mbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_12_12 = ARIMA(result.resid.dropna(), order=(12, 0, 12))\n",
        "results_12_12 = model_12_12.fit()\n",
        "print(results_12_12.summary())"
      ],
      "metadata": {
        "id": "hTmn3Kmi4FK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ar12 = ARIMA(result.resid.dropna(), order=(12, 0, 0))\n",
        "results_ar12 = model_ar12.fit()\n",
        "print(results_ar12.summary())"
      ],
      "metadata": {
        "id": "KE6Jyq55ih5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Ljung-Box Q test that checks for any remaining autocorrelation rules out remaining auto-correlation in the ARMA(12,12) model (the metric is zero) but there still seems to be some remaining autocorrelation on the AR(12). However, the JB test suggest that the AR(12) residuals look more Normal.\n",
        "\n",
        "Let's run with the ARMA(12,12) model. To validate, let's look at the residuals:"
      ],
      "metadata": {
        "id": "zrUIjpHo5UMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "residuals_12_12 = results_12_12.resid\n",
        "\n",
        "# Plot the residuals\n",
        "plt.plot(residuals_12_12)\n",
        "plt.title('Residuals of ARMA(12, 12) Model')\n",
        "plt.show()\n",
        "\n",
        "# Plot the histogram of residuals\n",
        "plt.hist(residuals_12_12)\n",
        "plt.title('Histogram of Residuals')\n",
        "plt.show()\n",
        "\n",
        "# Plot the ACF of residuals\n",
        "plot_acf(residuals_12_12, lags=20)\n",
        "plt.title('ACF of Residuals (ARMA(12, 12))')\n",
        "plt.show()\n",
        "\n",
        "# Plot the PACF of residuals\n",
        "plot_pacf(residuals_12_12, lags=20)\n",
        "plt.title('PACF of Residuals (ARMA(12, 12))')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YJSS5xQo5x2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So they look reasonably like **white noise**: The realizations look roughly Normal and the ACF and PACF don't show any residual autocorrelations."
      ],
      "metadata": {
        "id": "d9eRo05Z61xp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### S&P 500 Daily Data\n",
        "\n",
        "Let's now load and look at the stock data:"
      ],
      "metadata": {
        "id": "AMLLPVslGpy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dat_sandp = pd.read_csv('MSDIA_PredictiveModelingAndMachineLearning/GB886_VII_3_SanP500.csv')\n",
        "dat_sandp.head()"
      ],
      "metadata": {
        "id": "9R7oBitOrFcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is from 2/28/2023 (index zero) until 2/28/2024 (last index). Let's take a quick look:"
      ],
      "metadata": {
        "id": "hCdgIXO2Dz3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(dat_sandp)\n",
        "plt.title('Evolution of S and P Index 3/2023 to 3/2024')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IuyrVTx0rf3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, the first question is to check whether the time series is stationary. Here, **visual inspection** again makes it clear that the data appears not stationary, although there is also not a very clear deterministic trend.\n",
        "\n",
        "Let's check the ADF test:"
      ],
      "metadata": {
        "id": "KU53NhHrr5TN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = adfuller(dat_sandp)\n",
        "print('ADF Statistic: %f' % result[0])\n",
        "print('p-value: %f' % result[1])\n",
        "print('Critical Values:')\n",
        "for key, value in result[4].items():\n",
        "\tprint('\\t%s: %.3f' % (key, value))\n"
      ],
      "metadata": {
        "id": "N0lM46igsCJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, here the ADF test does not reject so we **do not** have stationarity. So, let's take the **first differences**, i.e., let's look at\n",
        "$$\n",
        "y^d_t = y_t - y_{t-1}\n",
        "$$\n",
        "and then work with the differenced series $\\{y^d_1,y^d_2,y^d_3,...\\}$:"
      ],
      "metadata": {
        "id": "ISbjp5pDK9pE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dat_sandp_diff = dat_sandp.diff().dropna()\n",
        "plt.plot(dat_sandp_diff)\n",
        "plt.title('First Differences of S and P Index 3/2023 to 3/2024')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ed1LkZ8OtF5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, there is no longer an indication of a trend. Let's run the ADF test on the differenced series."
      ],
      "metadata": {
        "id": "_3vAQYp0Lhf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = adfuller(dat_sandp_diff)\n",
        "print('ADF Statistic: %f' % result[0])\n",
        "print('p-value: %f' % result[1])\n",
        "print('Critical Values:')\n",
        "for key, value in result[4].items():\n",
        "\tprint('\\t%s: %.3f' % (key, value))"
      ],
      "metadata": {
        "id": "KO6BgDj_tO7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, that looks stationary. So, we can continue with our anaylsis using the differenced series."
      ],
      "metadata": {
        "id": "V758w3TULy5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot the ACF and the PACF:"
      ],
      "metadata": {
        "id": "-MYfuSEA7XH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_acf(dat_sandp_diff, lags=20)\n",
        "plt.title('ACF of Differenced Series')\n",
        "plt.show()\n",
        "\n",
        "plot_pacf(dat_sandp_diff, lags=20)\n",
        "plt.title('PACF of Differenced Series')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qQaYsRRh7hwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we don't detect much correlation or autocorrelation. Let's look at a histogram:"
      ],
      "metadata": {
        "id": "_q5kJw887xl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(dat_sandp_diff)\n",
        "plt.title('Histogram of Differenced Series')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SeYDOx4J9vqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, all in all, it seems reasonable to assume that the series is white noise. Let's look at the mean and variance:"
      ],
      "metadata": {
        "id": "DouJVnPg9ra8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_diff = dat_sandp_diff.mean()\n",
        "std_diff = dat_sandp_diff.std()\n",
        "\n",
        "# Calculate the standard error of the mean\n",
        "n = len(dat_sandp_diff)\n",
        "se_mean = std_diff / np.sqrt(n)\n",
        "\n",
        "# Calculate the 95% confidence interval for the mean\n",
        "lower_mean = mean_diff - 1.96 * se_mean\n",
        "upper_mean = mean_diff + 1.96 * se_mean\n",
        "\n",
        "print(\"Point Estimate for Mean:\", mean_diff.iloc[0])\n",
        "print(\"95% Confidence Interval for Mean:\", (lower_mean.iloc[0], upper_mean.iloc[0]))\n",
        "print(\"Standard Deviation:\", std_diff.iloc[0])"
      ],
      "metadata": {
        "id": "8Gl4dvME9TEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, the mean is significantly different from zero. Our final model for the series is:\n",
        "$$\n",
        "S_t = S_{t-1} + 4.45836 + 33.8281 \\times \\varepsilon_t,\\;\\;\\varepsilon_t\\sim N(0,1)\n",
        "$$\n",
        "Such a time series is called a **random walk with drift**."
      ],
      "metadata": {
        "id": "77gZdnHB9SvW"
      }
    }
  ]
}